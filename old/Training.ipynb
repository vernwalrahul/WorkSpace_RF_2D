{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Pre-Processing\n",
      "\n",
      "import os\n",
      "import argparse\n",
      "import networkx as nx\n",
      "import math        \n",
      "import numpy as np\n",
      "\n",
      "def state_to_numpy(state):\n",
      "    strlist = state.split()\n",
      "    val_list = [float(s) for s in strlist]\n",
      "    return np.array(val_list)\n",
      "\n",
      "def list_all_dir(data_dir):\n",
      "    task_dirs = os.listdir(data_dir)\n",
      "\n",
      "    list_dir = []\n",
      "    for task_dir in task_dirs:\n",
      "        env_dirs = os.listdir(data_dir+\"/\"+task_dir)\n",
      "        for env_dir in env_dirs:\n",
      "            list_dir.append(data_dir +\"/\"+ task_dir +\"/\"+ env_dir)\n",
      "    return list_dir  \n",
      "\n",
      "def process_it(G, directory):\n",
      "    start = np.loadtxt(directory+\"/start_nodes.txt\")\n",
      "    goal = np.loadtxt(directory+\"/goal_nodes.txt\")\n",
      "    occ_grid = np.loadtxt(directory+\"/occ_grid.txt\")\n",
      "    # occ_grid = occ_grid.split(\",\")\n",
      "    path_nodes = []\n",
      "    i = 0\n",
      "    all_data = []\n",
      "    with open(directory + \"/path_nodes.txt\", 'r') as file:\n",
      "        lines  = file.readlines()\n",
      "        for line in lines:\n",
      "            line = line.strip('\\n')\n",
      "#             print(line)\n",
      "#             print(\"\\n\\n\")\n",
      "            \n",
      "            s = state_to_numpy(G.node[str(int(start[i]))]['state'])\n",
      "            g = state_to_numpy(G.node[str(int(goal[i]))]['state'])\n",
      "            og = occ_grid[i]\n",
      "            path_nodes = str(line).split(\",\")\n",
      "            # print(path_nodes)\n",
      "            for path_node in path_nodes:\n",
      "                if(path_node=='-1'):\n",
      "                    continue\n",
      "                node_conf = state_to_numpy(G.node[path_node]['state'])\n",
      "                curr_node = np.array([])\n",
      "                # print(\"Data = \",node_conf, s, g, occ_grid)\n",
      "#                     print(\"\\n\")\n",
      "#                     print(\"node_conf = \", node_conf, \" s = \", s, \" g = \",g)\n",
      "\n",
      "                curr_node = np.concatenate((node_conf, s, g, og))\n",
      "#                     print(\"shape of curr_node = \", curr_node.shape)\n",
      "                all_data.append(curr_node)\n",
      "            i+=1\n",
      "    return all_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Workspace problem with several narrow gaps\n",
      "\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.patches as patches\n",
      "import matplotlib.gridspec as gridspec\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "import os\n",
      "import csv\n",
      "from random import randint, random\n",
      "import time\n",
      "\n",
      "# (restrict tensorflow memory growth)\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
      "config = tf.ConfigProto()\n",
      "config.gpu_options.allow_growth=True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# neural network parameters\n",
      "mb_size = 256\n",
      "h_Q_dim = 512\n",
      "h_P_dim = 512\n",
      "\n",
      "c = 0\n",
      "# learning rate\n",
      "lr = 1e-4\n",
      "\n",
      "# problem dimensions\n",
      "dim = 2\n",
      "dataElements = dim*3 + 400 # sample (7D), init (7D), goal (7D), cond (occ_grid) //total = 206\n",
      "\n",
      "z_dim = 2 # latent\n",
      "X_dim = dim # samples\n",
      "y_dim = dim # reconstruction of the original point\n",
      "c_dim = dataElements - dim # dimension of conditioning variable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "G = nx.read_graphml(\"graphs_2d/dense_graph.graphml\")\n",
      "data_dir = \"dataset\"\n",
      "\n",
      "directory = data_dir\n",
      "print(directory)\n",
      "final_data = []\n",
      "flag = 0\n",
      "\n",
      "data = np.array(process_it(G, directory))\n",
      "# np.random.shuffle(data)\n",
      "print(\"shape of array: \",data.shape)\n",
      "\n",
      "x = data[5,:]\n",
      "# data = np.repeat([x], 150, axis = 0)\n",
      "print(\"data = \", data.shape)\n",
      "numEntries = data.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dataset\n",
        "('shape of array: ', (15126, 406))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('data = ', (15126, 406))\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split the inputs and conditions into test train (to be processed in the next step into an occupancy grid representation)\n",
      "ratioTestTrain = 0.001;\n",
      "numTrain = int(numEntries*ratioTestTrain)\n",
      "\n",
      "np.random.shuffle(data[0:numTrain,:])\n",
      "np.random.shuffle(data[numTrain:numEntries,:])\n",
      "\n",
      "X_train = data[0:numTrain,0:dim] # state: x, y, z, xdot, ydot, zdot\n",
      "c_train = data[0:numTrain,dim:dataElements] # conditions: gaps, init (6), goal (6)\n",
      "\n",
      "X_test = data[numTrain:numEntries,0:dim]\n",
      "c_test = data[numTrain:numEntries,dim:dataElements]\n",
      "\n",
      "#########################################################\n",
      "c_train1 = []\n",
      "c_test1 = []\n",
      "c_train1 = c_train\n",
      "c_test1 = c_test\n",
      "#########################################################\n",
      "numTest = X_test.shape[0]\n",
      "# print(\"shape of final obstacle = \",obs.shape)\n",
      "print(\"shape of c_train1 = \", c_train1.shape)\n",
      "print(\"shape of c_test1 = \",c_test1.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('shape of c_train1 = ', (15, 404))\n",
        "('shape of c_test1 = ', (15111, 404))\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define networks\n",
      "print(\"X_dim = \",X_dim)\n",
      "print(\"c_dim = \",c_dim)\n",
      "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
      "c = tf.placeholder(tf.float32, shape=[None, c_dim])\n",
      "    \n",
      "# Q\n",
      "inputs_Q = tf.concat(axis=1, values=[X,c])\n",
      "\n",
      "dense_Q1 = tf.layers.dense(inputs=inputs_Q, units=h_Q_dim, activation=tf.nn.relu)\n",
      "dropout_Q1 = tf.layers.dropout(inputs=dense_Q1, rate=0.5)\n",
      "dense_Q2 = tf.layers.dense(inputs=dropout_Q1, units=h_Q_dim, activation=tf.nn.relu)\n",
      "\n",
      "z_mu = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_mu\n",
      "z_logvar = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_logvar\n",
      "\n",
      "# P\n",
      "eps = tf.random_normal(shape=tf.shape(z_mu))\n",
      "z = z_mu + tf.exp(z_logvar / 2) * eps\n",
      "inputs_P = tf.concat(axis=1, values=[z,c])\n",
      "\n",
      "dense_P1 = tf.layers.dense(inputs=inputs_P, units=h_P_dim, activation=tf.nn.relu)\n",
      "dropout_P1 = tf.layers.dropout(inputs=dense_P1, rate=0.5)\n",
      "dense_P2 = tf.layers.dense(inputs=dropout_P1, units=h_P_dim, activation=tf.nn.relu)\n",
      "\n",
      "y = tf.layers.dense(inputs=dense_P2, units=X_dim) # fix to also output y\n",
      "\n",
      "# training\n",
      "########### comment in the one with 0 weight and uncomment the other ###########\n",
      "w = [[1, 1]];\n",
      "# w = [[1, 1, 1, 0, 0, 0]];\n",
      "recon_loss = tf.losses.mean_squared_error(labels=X, predictions=y, weights=w)\n",
      "\n",
      "# TODO: fix loss function for angles going around\n",
      "kl_loss = 10**-4 * 2 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
      "\n",
      "cvae_loss = tf.reduce_mean(kl_loss + recon_loss)\n",
      "\n",
      "train_step = tf.train.AdamOptimizer(lr).minimize(cvae_loss)\n",
      "\n",
      "sess = tf.Session(config=config)\n",
      "sess.run(tf.global_variables_initializer())\n",
      "it = 0;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('X_dim = ', 2)\n",
        "('c_dim = ', 404)\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saver = tf.train.Saver()\n",
      "path_ = os.getcwd() + \"/checkpoints_z2_1l/model.ckpt\"\n",
      "print(\"path = \",path_)\n",
      "print(\"numTrain = \",numTrain)\n",
      "try:\n",
      "    saver.restore(sess, path_)\n",
      "    print(\"Model Restored!!\")\n",
      "except Exception as e:\n",
      "    print(\"Could not restore checkpoint!\")\n",
      "    print(e)\n",
      "x1 = []\n",
      "y1 = []    \n",
      "print(\"z_dim = \", z_dim)\n",
      "print(\"c_dim = \", c_dim)\n",
      "print(\"c_train = \", c_train.shape)\n",
      "for it in range(it,it+600001):\n",
      "#     print(\"c_dim = \",c_dim)\n",
      "    # randomly generate batches\n",
      "    batch_elements = [randint(0,numTrain-1) for n in range(0,mb_size)]\n",
      "    X_mb = X_train[batch_elements,:]\n",
      "    c_mb = c_train1[batch_elements,:]\n",
      "\n",
      "    _, loss = sess.run([train_step, cvae_loss], feed_dict={X: X_mb, c: c_mb})\n",
      "\n",
      "    if it % 1000 == 0:\n",
      "        print('Iter: {}'.format(it))\n",
      "        print('Loss: {:.4}'. format(loss))\n",
      "        x1.append(it)\n",
      "        y1.append(loss)\n",
      "    if it % 1000 == 0:    \n",
      "        saver.save(sess, path_)\n",
      "        print(\"saved session to \", path_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('path = ', '/home/vernwalrahul/projects/WorkSpace_Hlaton_2D/checkpoints_z2_1l/model.ckpt')\n",
        "('numTrain = ', 15)\n",
        "Could not restore checkpoint!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Key beta1_power_9 not found in checkpoint\n",
        "\t [[Node: save_7/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_7/Const_0_0, save_7/RestoreV2/tensor_names, save_7/RestoreV2/shape_and_slices)]]\n",
        "\n",
        "Caused by op u'save_7/RestoreV2', defined at:\n",
        "  File \"<string>\", line 1, in <module>\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/kernelapp.py\", line 468, in main\n",
        "    app.start()\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/kernelapp.py\", line 458, in start\n",
        "    ioloop.IOLoop.instance().start()\n",
        "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 160, in start\n",
        "    super(ZMQIOLoop, self).start()\n",
        "  File \"/usr/lib/python2.7/dist-packages/tornado/ioloop.py\", line 672, in start\n",
        "    self._handlers[fd](fd, events)\n",
        "  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 302, in wrapped\n",
        "    ret = fn(*args, **kwargs)\n",
        "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n",
        "    self._handle_recv()\n",
        "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n",
        "    self._run_callback(callback, msg)\n",
        "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n",
        "    callback(*args, **kwargs)\n",
        "  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 302, in wrapped\n",
        "    ret = fn(*args, **kwargs)\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/ipkernel.py\", line 279, in dispatcher\n",
        "    return self.dispatch_shell(stream, msg)\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/ipkernel.py\", line 247, in dispatch_shell\n",
        "    handler(stream, idents, msg)\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/ipkernel.py\", line 396, in execute_request\n",
        "    shell.run_cell(code, store_history=store_history, silent=silent)\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2660, in run_cell\n",
        "    interactivity=interactivity, compiler=compiler)\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2764, in run_ast_nodes\n",
        "    if self.run_code(code):\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2820, in run_code\n",
        "    exec code_obj in self.user_global_ns, self.user_ns\n",
        "  File \"<ipython-input-100-607784fa1c9b>\", line 1, in <module>\n",
        "    saver = tf.train.Saver()\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1338, in __init__\n",
        "    self.build()\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1347, in build\n",
        "    self._build(self._filename, build_save=True, build_restore=True)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1384, in _build\n",
        "    build_save=build_save, build_restore=build_restore)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 835, in _build_internal\n",
        "    restore_sequentially, reshape)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 472, in _AddRestoreOps\n",
        "    restore_sequentially)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 886, in bulk_restore\n",
        "    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n",
        "    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
        "    op_def=op_def)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n",
        "    op_def=op_def)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n",
        "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
        "\n",
        "NotFoundError (see above for traceback): Key beta1_power_9 not found in checkpoint\n",
        "\t [[Node: save_7/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_7/Const_0_0, save_7/RestoreV2/tensor_names, save_7/RestoreV2/shape_and_slices)]]\n",
        "\n",
        "('z_dim = ', 2)\n",
        "('c_dim = ', 404)\n",
        "('c_train = ', (15, 404))\n",
        "Iter: 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.1185\n",
        "('saved session to ', '/home/vernwalrahul/projects/WorkSpace_Hlaton_2D/checkpoints_z2_1l/model.ckpt')"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot the latent space\n",
      "num_viz = 300\n",
      "print(\"c_test.shape = \",c_test.shape)\n",
      "# print(c_test[:,:4])\n",
      "vizIdx = randint(0,numTrain-1);\n",
      "# vizIdx = 3\n",
      "print vizIdx\n",
      "c_sample_seed = c_train[vizIdx,:]\n",
      "print(\"x_train = \", X_train[vizIdx,:])\n",
      "occ_g = c_train[vizIdx,4:].reshape(20,20)\n",
      "# print(c_sample_seed[:4])\n",
      "init = c_sample_seed[:2]\n",
      "goal = c_sample_seed[2:4]\n",
      "c_sample = np.repeat([c_sample_seed],num_viz,axis=0)\n",
      "\n",
      "print(\"c_sample.shape = \",c_sample.shape)\n",
      "# directly sample from the latent space (preferred, what we will use in the end)\n",
      "y_viz, z_viz = sess.run([y, z], feed_dict={z: np.random.randn(num_viz, z_dim), c: c_sample})\n",
      "\n",
      "fig1 = plt.figure(figsize=(10,6), dpi=80)\n",
      "ax1 = fig1.add_subplot(111, aspect='equal')\n",
      "\n",
      "plt.scatter(y_viz[:,1],y_viz[:,0], color=\"green\", s=20)\n",
      "\n",
      "for i in range(20):\n",
      "        for j in range(20):\n",
      "            if(occ_g[i,j]==0):\n",
      "                ax1.add_patch(patches.Rectangle(\n",
      "                (j/20.0, i/20.0),   # (x,y)\n",
      "                0.05,          # width\n",
      "                0.05,          # height\n",
      "                alpha=0.6\n",
      "                ))\n",
      "\n",
      "plt.scatter(init[1], init[0], color=\"red\", s=100, edgecolors='black') # init\n",
      "plt.scatter(goal[1], goal[0], color=\"blue\", s=100, edgecolors='black') # goal\n",
      "\n",
      "plt.xlim(0,1)\n",
      "plt.ylim(0,1)\n",
      "\n",
      "# plt.savefig(\"output_\"+str(vizIdx)+\".jpg\", bbox_inches='tight')\n",
      "plt.show()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('c_test.shape = ', (15120, 404))\n",
        "0\n",
        "('x_train = ', array([0.55613813, 0.49369176]))\n",
        "('c_sample.shape = ', (300, 404))\n"
       ]
      }
     ],
     "prompt_number": 96
    }
   ],
   "metadata": {}
  }
 ]
}