{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Processing\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import networkx as nx\n",
    "import math        \n",
    "import numpy as np\n",
    "\n",
    "def state_to_numpy(state):\n",
    "    strlist = state.split()\n",
    "    val_list = [float(s) for s in strlist]\n",
    "    return np.array(val_list)\n",
    "\n",
    "def list_all_dir(data_dir):\n",
    "    task_dirs = os.listdir(data_dir)\n",
    "\n",
    "    list_dir = []\n",
    "    for task_dir in task_dirs:\n",
    "        env_dirs = os.listdir(data_dir+\"/\"+task_dir)\n",
    "        for env_dir in env_dirs:\n",
    "            list_dir.append(data_dir +\"/\"+ task_dir +\"/\"+ env_dir)\n",
    "    return list_dir  \n",
    "\n",
    "def process_it(G, directory):\n",
    "    start = np.loadtxt(directory+\"/start_nodes.txt\")\n",
    "    goal = np.loadtxt(directory+\"/goal_nodes.txt\")\n",
    "    occ_grid = np.loadtxt(directory+\"/occ_grid.txt\")\n",
    "    # occ_grid = occ_grid.split(\",\")\n",
    "    path_nodes = []\n",
    "    i = 0\n",
    "    all_data = []\n",
    "    with open(directory + \"/path_nodes.txt\", 'r') as file:\n",
    "        lines  = file.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip('\\n')\n",
    "#             print(line)\n",
    "#             print(\"\\n\\n\")\n",
    "            \n",
    "            s = state_to_numpy(G.node[str(int(start[i]))]['state'])\n",
    "            g = state_to_numpy(G.node[str(int(goal[i]))]['state'])\n",
    "            og = occ_grid[i]\n",
    "            path_nodes = str(line).split(\",\")\n",
    "            # print(path_nodes)\n",
    "            for path_node in path_nodes:\n",
    "                if(path_node=='-1'):\n",
    "                    continue\n",
    "                node_conf = state_to_numpy(G.node[path_node]['state'])\n",
    "                curr_node = np.array([])\n",
    "                # print(\"Data = \",node_conf, s, g, occ_grid)\n",
    "#                     print(\"\\n\")\n",
    "#                     print(\"node_conf = \", node_conf, \" s = \", s, \" g = \",g)\n",
    "\n",
    "                curr_node = np.concatenate((node_conf, s, g, og))\n",
    "#                     print(\"shape of curr_node = \", curr_node.shape)\n",
    "                all_data.append(curr_node)\n",
    "            i+=1\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace problem with several narrow gaps\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "import csv\n",
    "from random import randint, random, seed\n",
    "import time\n",
    "\n",
    "# (restrict tensorflow memory growth)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "# neural network parameters\n",
    "mb_size = 256\n",
    "h_Q_dim = 512\n",
    "h_P_dim = 512\n",
    "\n",
    "c = 0\n",
    "# learning rate\n",
    "lr = 1e-4\n",
    "\n",
    "# problem dimensions\n",
    "dim = 2\n",
    "dataElements = dim*3 + 100 # sample (2D), init(2D), goal(2D), occup_grid(400) \n",
    "\n",
    "z_dim = 2 # latent\n",
    "X_dim = dim # samples\n",
    "y_dim = dim # reconstruction of the original point\n",
    "c_dim = dataElements - dim # dimension of conditioning variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "('shape of array: ', (39848, 106))\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml(\"graphs/dense_graph.graphml\")\n",
    "data_dir = \"dataset\"\n",
    "\n",
    "directory = data_dir\n",
    "print(directory)\n",
    "final_data = []\n",
    "flag = 0\n",
    "\n",
    "data = np.array(process_it(G, directory))\n",
    "\n",
    "# np.random.shuffle(data)\n",
    "print(\"shape of array: \",data.shape)\n",
    "\n",
    "numEntries = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('shape of c_train1 = ', (15939, 104))\n",
      "('shape of c_test1 = ', (23909, 104))\n"
     ]
    }
   ],
   "source": [
    "# split the inputs and conditions into test train (to be processed in the next step into an occupancy grid representation)\n",
    "ratioTestTrain = 0.4;\n",
    "numTrain = int(numEntries*ratioTestTrain)\n",
    "\n",
    "X_train = data[0:numTrain,0:dim] # state: x, y, z, xdot, ydot, zdot\n",
    "c_train = data[0:numTrain,dim:dataElements] # conditions: gaps, init (6), goal (6)\n",
    "# print(\"c_train = \",c_train[:,:4])\n",
    "\n",
    "X_test = data[numTrain:numEntries,0:dim]\n",
    "c_test = data[numTrain:numEntries,dim:dataElements]\n",
    "\n",
    "#########################################################\n",
    "c_train1 = []\n",
    "c_test1 = []\n",
    "c_train1 = c_train\n",
    "c_test1 = c_test\n",
    "#########################################################\n",
    "numTest = X_test.shape[0]\n",
    "# print(data[:,:6])\n",
    "# print(c_test[:,:4])\n",
    "\n",
    "# print(\"shape of final obstacle = \",obs.shape)\n",
    "print(\"shape of c_train1 = \", c_train1.shape)\n",
    "print(\"shape of c_test1 = \",c_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_dim = ', 2)\n",
      "('c_dim = ', 104)\n"
     ]
    }
   ],
   "source": [
    "# define networks\n",
    "print(\"X_dim = \",X_dim)\n",
    "print(\"c_dim = \",c_dim)\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "c = tf.placeholder(tf.float32, shape=[None, c_dim])\n",
    "    \n",
    "# Q\n",
    "inputs_Q = tf.concat(axis=1, values=[X,c])\n",
    "\n",
    "dense_Q1 = tf.layers.dense(inputs=inputs_Q, units=h_Q_dim, activation=tf.nn.relu)\n",
    "dropout_Q1 = tf.layers.dropout(inputs=dense_Q1, rate=0.5)\n",
    "dense_Q2 = tf.layers.dense(inputs=dropout_Q1, units=h_Q_dim, activation=tf.nn.relu)\n",
    "\n",
    "z_mu = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_mu\n",
    "z_logvar = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_logvar\n",
    "\n",
    "# P\n",
    "eps = tf.random_normal(shape=tf.shape(z_mu))\n",
    "z = z_mu + tf.exp(z_logvar / 2) * eps\n",
    "inputs_P = tf.concat(axis=1, values=[z,c])\n",
    "\n",
    "dense_P1 = tf.layers.dense(inputs=inputs_P, units=h_P_dim, activation=tf.nn.relu)\n",
    "dropout_P1 = tf.layers.dropout(inputs=dense_P1, rate=0.5)\n",
    "dense_P2 = tf.layers.dense(inputs=dropout_P1, units=h_P_dim, activation=tf.nn.relu)\n",
    "\n",
    "y = tf.layers.dense(inputs=dense_P2, units=X_dim) # fix to also output y\n",
    "\n",
    "# training\n",
    "########### comment in the one with 0 weight and uncomment the other ###########\n",
    "w = [[1, 1]];\n",
    "# w = [[1, 1, 1, 0, 0, 0]];\n",
    "recon_loss = tf.losses.mean_squared_error(labels=X, predictions=y, weights=w)\n",
    "\n",
    "# TODO: fix loss function for angles going around\n",
    "kl_loss = 10**-4 * 2 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
    "\n",
    "cvae_loss = tf.reduce_mean(kl_loss + recon_loss)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cvae_loss)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "it = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('path = ', '/home/vernwalrahul/projects/WorkSpace_Hlaton_2D/checkpoints_NS_less/model.ckpt')\n",
      "('numTrain = ', 15939)\n",
      "Model Restored!!\n",
      "('z_dim = ', 2)\n",
      "('c_dim = ', 104)\n",
      "('c_train = ', (15939, 104))\n",
      "Iter: 0\n",
      "Loss: 0.001627\n",
      "('recon_loss = ', 0.00039443915)\n",
      "('saved session to ', '/home/vernwalrahul/projects/WorkSpace_Hlaton_2D/checkpoints_NS_less/model.ckpt')"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d9c4f82879a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mc_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_train1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_elements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvae_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc_mb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "path_ = os.getcwd() + \"/checkpoints_NS_less/model.ckpt\"\n",
    "print(\"path = \",path_)\n",
    "print(\"numTrain = \",numTrain)\n",
    "try:\n",
    "    saver.restore(sess, path_)\n",
    "    print(\"Model Restored!!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not restore checkpoint!\")\n",
    "    print(e)\n",
    "x1 = []\n",
    "y1 = []    \n",
    "print(\"z_dim = \", z_dim)\n",
    "print(\"c_dim = \", c_dim)\n",
    "print(\"c_train = \", c_train.shape)\n",
    "for it in range(it,it+600001):\n",
    "#     print(\"c_dim = \",c_dim)\n",
    "    # randomly generate batches\n",
    "    batch_elements = [randint(0,numTrain-1) for n in range(0,mb_size)]\n",
    "    X_mb = X_train[batch_elements,:]\n",
    "    c_mb = c_train1[batch_elements,:]\n",
    "\n",
    "    _, loss, r = sess.run([train_step, cvae_loss, recon_loss], feed_dict={X: X_mb, c: c_mb})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('Loss: {:.4}'. format(loss))\n",
    "        x1.append(it)\n",
    "        y1.append(loss)\n",
    "        print(\"recon_loss = \", r)\n",
    "    if it % 1000 == 0:    \n",
    "        saver.save(sess, path_)\n",
    "        print(\"saved session to \", path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]]\n",
      "[[1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]]\n",
      "[[1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]]\n",
      "[[1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 1 0 0 0 0 0]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]]\n",
      "[[1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]]\n",
      "[[1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 1 0 0 0 0 0]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#to check if a node is free\n",
    "def is_free(node_pos, obstacles):\n",
    "    flag = 1\n",
    "    eps = 0.04\n",
    "    for obs in obstacles:\n",
    "        x1, y1, x2, y2 = obs\n",
    "        if(node_pos[0] < x2 + eps and node_pos[0] > x1 - eps):\n",
    "            if(node_pos[1] < y2 + eps and node_pos[1] > y1 - eps):\n",
    "                flag = 0\n",
    "                return flag\n",
    "    return flag\n",
    "\n",
    "################Create Occ_Grid\n",
    "def get_occ_grid(obstacles):\n",
    "    occ_grid = np.ones((10,10), dtype=int)\n",
    "    eps = 0.05\n",
    "    for i in range(0,10):\n",
    "        for j in range(0, 10):\n",
    "            if(not (is_free((i/10.0+eps,j/10.0+eps), obstacles))):\n",
    "                occ_grid[i,j] = 0\n",
    "            else:\n",
    "                occ_grid[i,j] = 1\n",
    "    return occ_grid.ravel()\n",
    "\n",
    "obs1 = [0.0, 0.1, 0.4, 0.2]\n",
    "obs2 = [0.5, 0.1, 0.6, 0.2]\n",
    "obs3 = [0.7, 0.1, 1.0, 0.2]\n",
    "\n",
    "init_ = np.array([0.05 , 0.95])\n",
    "goal_ = np.array([0.95 , 0.95])\n",
    "\n",
    "c_here = []\n",
    "for x in range(1,7):\n",
    "    obs4 = [x/10.0, 0.5, x/10.0+0.1, 1.0]\n",
    "    obs5 = [x/10.0, 0.2, x/10.0+0.1, 0.4]\n",
    "    obs6 = [x/10.0, 0.0, x/10.0+0.1, 0.1]\n",
    "    \n",
    "    obstacles = [obs1, obs2, obs3, obs4, obs5, obs6]\n",
    "    curr_occ_grid = np.array(get_occ_grid(obstacles))\n",
    "    print(curr_occ_grid.reshape(10,10))\n",
    "    c_here.append(np.concatenate((init_, goal_, curr_occ_grid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('c_test.shape = ', (23909, 104))\n",
      "('c_train.shape = ', (15939, 104))\n",
      "7950\n",
      "('c_sample_seed = ', array([0.75920959, 0.55289302, 0.04583068, 0.45504209]))\n",
      "('Train Sample = ', array([0.46477599, 0.35856289]))\n",
      "('c_sample.shape = ', (200, 104))\n"
     ]
    }
   ],
   "source": [
    "# plot the latent space\n",
    "num_viz = 200\n",
    "# seed(1000)\n",
    "print(\"c_test.shape = \",c_test.shape)\n",
    "print(\"c_train.shape = \",c_train.shape)\n",
    "# print(c_test[:,:4])\n",
    "vizIdx = randint(0,numTrain-1);\n",
    "vizIdx = 7950\n",
    "print vizIdx\n",
    "c_sample_seed = c_test[vizIdx,:]\n",
    "print(\"c_sample_seed = \", c_sample_seed[:4])\n",
    "occ_g = c_sample_seed[4:].reshape(10,10)\n",
    "\n",
    "# c_here = np.array(c_here)\n",
    "# c_sample_seed = c_here[0,:]\n",
    "# occ_g = c_here[0,4:].reshape(10,10)\n",
    "\n",
    "ts = X_test[vizIdx,:2]\n",
    "print(\"Train Sample = \", ts)\n",
    "\n",
    "# c_sample_seed = c_test[vizIdx,:]\n",
    "# occ_g = c_test[vizIdx,4:].reshape(20,20)\n",
    "# print(\"Testing Sample = \",X_test[vizIdx,:2])\n",
    "\n",
    "# print(c_sample_seed[:4])\n",
    "init = c_sample_seed[:2]\n",
    "goal = c_sample_seed[2:4]\n",
    "c_sample = np.repeat([c_sample_seed],num_viz,axis=0)\n",
    "\n",
    "print(\"c_sample.shape = \",c_sample.shape)\n",
    "# directly sample from the latent space (preferred, what we will use in the end)\n",
    "y_viz, z_viz = sess.run([y, z], feed_dict={z: np.random.randn(num_viz, z_dim), c: c_sample})\n",
    "\n",
    "fig1 = plt.figure(figsize=(10,6), dpi=80)\n",
    "ax1 = fig1.add_subplot(111, aspect='equal')\n",
    "\n",
    "plt.scatter(y_viz[:,0],y_viz[:,1], color=\"green\", s=20)\n",
    "\n",
    "for i in range(10):\n",
    "        for j in range(10):\n",
    "            if(occ_g[i,j]==0):\n",
    "                ax1.add_patch(patches.Rectangle(\n",
    "                (i/10.0, j/10.0),   # (x,y)\n",
    "                0.1,          # width\n",
    "                0.1,          # height\n",
    "                alpha=0.6\n",
    "                ))\n",
    "\n",
    "plt.scatter(init[0], init[1], color=\"red\", s=100, edgecolors='black') # init\n",
    "plt.scatter(goal[0], goal[1], color=\"blue\", s=100, edgecolors='black') # goal\n",
    "plt.scatter(ts[0], ts[1], color=\"orange\", s=50, edgecolors='black') # goal\n",
    "\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "# plt.savefig(\"collection/ratio_0.4/training_\"+str(vizIdx)+\".jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01653381 0.34530272 0.45061584 ... 1.         1.         1.        ]\n",
      " [0.95452209 0.98499179 0.08831115 ... 1.         1.         1.        ]\n",
      " [0.05364318 0.58672933 0.21526428 ... 1.         1.         1.        ]\n",
      " ...\n",
      " [0.44915099 0.65485919 0.89788146 ... 1.         0.         1.        ]\n",
      " [0.01458068 0.96121493 0.87053771 ... 1.         1.         1.        ]\n",
      " [0.67961974 0.3132954  0.00286193 ... 1.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "conditions = np.loadtxt(\"test_cases.txt\", delimiter = \" \")\n",
    "print(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_numpy(state):\n",
    "    strlist = state.split()\n",
    "#     print(\"strlist = \", strlist)\n",
    "    val_list = [float(s) for s in strlist]\n",
    "    return np.array(val_list)\n",
    "\n",
    "def edge_to_configs(state1, state2):\n",
    "    EDGE_DISCRETIZATION = 20\n",
    "    config1 = state_to_numpy(state1)\n",
    "    config2 = state_to_numpy(state2)\n",
    "\n",
    "    diff = config2 - config1\n",
    "    step = diff/EDGE_DISCRETIZATION\n",
    "\n",
    "    to_check = list()\n",
    "    to_check.append(config1)\n",
    "\n",
    "    for i in xrange(EDGE_DISCRETIZATION - 1):\n",
    "        conf = config1 + step*(i+1)\n",
    "        to_check.append(conf)\n",
    "\n",
    "    return to_check\n",
    "\n",
    "#get output node posns\n",
    "def get_o_node_posns(c_sample_seed, num_viz, count):\n",
    "#     return []\n",
    "    init = c_sample_seed[:2]\n",
    "    goal = c_sample_seed[2:4]\n",
    "    occ_grid = c_sample_seed[4:].reshape(10,10)\n",
    "    c_sample = np.repeat([c_sample_seed],num_viz,axis=0)\n",
    "    y_viz, z_viz = sess.run([y, z], feed_dict={z: np.random.randn(num_viz, z_dim), c: c_sample})\n",
    "    \n",
    "    fig1 = plt.figure(figsize=(10,6), dpi=80)\n",
    "    ax1 = fig1.add_subplot(111, aspect='equal')\n",
    "    \n",
    "    free_nodes = []\n",
    "    y_viz = np.array(y_viz)\n",
    "    y_viz = list(y_viz)\n",
    "#     print(\"y_viz = \",y_viz)\n",
    "    for cc in y_viz:\n",
    "            eps = 0.015\n",
    "            x_, y_ = float(cc[0]), float(cc[1])\n",
    "            \n",
    "            x_ = min(0.95, cc[0])\n",
    "            y_ = min(0.95, cc[1])\n",
    "            if(occ_grid[int((x_+eps)*10), int((y_+eps)*10)]==0 or occ_grid[int((x_-eps)*10), int((y_-eps)*10)]==0):\n",
    "                continue\n",
    "            else:\n",
    "                free_nodes.append(cc)\n",
    "    y_viz = np.array(free_nodes)\n",
    "    \n",
    "    plt.scatter(y_viz[:,0],y_viz[:,1], color=\"green\", s=20)\n",
    "    \n",
    "    for i in range(10):\n",
    "            for j in range(10):\n",
    "                if(occ_grid[i,j]==0):\n",
    "                    ax1.add_patch(patches.Rectangle(\n",
    "                    (i/10.0, j/10.0),   # (x,y)\n",
    "                    0.1,          # width\n",
    "                    0.1,          # height\n",
    "                    alpha=0.6\n",
    "                    ))\n",
    "    \n",
    "    plt.scatter(init[0], init[1], color=\"red\", s=100, edgecolors='black') # init\n",
    "    plt.scatter(goal[0], goal[1], color=\"blue\", s=100, edgecolors='black') # goal\n",
    "    \n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(str(count))\n",
    "    plt.savefig(\"RF_n3000_\"+str(count)+\".jpg\", bbox_inches='tight')\n",
    "#     plt.show()\n",
    "    \n",
    "    return y_viz\n",
    "\n",
    "#load shallow_graph\n",
    "def load_halton_samples():\n",
    "    shallow_G = nx.read_graphml(\"graphs/halton2D100_1.graphml\")\n",
    "    shallow_G.remove_edges_from(list(shallow_G.edges()))\n",
    "    return shallow_G\n",
    "\n",
    "def remove_invalid_edges(G, occ_grid):\n",
    "    \n",
    "    # print(\"total no of edges = \", len(list(G.edges())))\n",
    "    to_remove = []\n",
    "    for edge in G.edges():\n",
    "        u, v = edge\n",
    "        state1 = G.node[u]['state']\n",
    "        state2 = G.node[v]['state']\n",
    "        configs_to_check = edge_to_configs(state1,state2)\n",
    "\n",
    "        edge_free = 1\n",
    "        eps = 0.015\n",
    "        for cc in configs_to_check:\n",
    "            cc[0] = min(0.95, cc[0])\n",
    "            cc[1] = min(0.95, cc[1])\n",
    "            if(occ_grid[int((cc[0]+eps)*10), int((cc[1]+eps)*10)]==0 or occ_grid[int((cc[0]-eps)*10), int((cc[1]-eps)*10)]==0):\n",
    "                edge_free = 0\n",
    "                break\n",
    "        if(not edge_free):\n",
    "            to_remove.append((u, v))\n",
    "\n",
    "    for r in to_remove:\n",
    "        G.remove_edge(r[0], r[1])\n",
    "    \n",
    "    print(\"removed \", len(to_remove), \"edges\")\n",
    "        \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_weight(s, g):\n",
    "    return sqrt(np.sum((s-g)**2))\n",
    "\n",
    "def connect_knn(G, K):\n",
    "    print(\"no of nodes = \", len(list(G.nodes())))\n",
    "    for node in G.nodes():\n",
    "        state = G.node[node]['state']\n",
    "        conf = state_to_numpy(state)\n",
    "        G1 = G.copy()\n",
    "\n",
    "        for k in range(K):\n",
    "            w = 1000000\n",
    "            sn = None\n",
    "            for node1 in G1.nodes():\n",
    "            \tif(node == node1):\n",
    "            \t\tcontinue\n",
    "                state1 = G1.node[node1]['state']\n",
    "#                 print(\"node1 = \",node1)\n",
    "#                 print(\"state1 = \",state1)\n",
    "                \n",
    "                conf1  = state_to_numpy(state1)\n",
    "                if(calc_weight(conf, conf1) < w):\n",
    "                    w = calc_weight(conf, conf1)\n",
    "                    sn = node1\n",
    "\n",
    "            # if(check_for_collision(node, sn)==1):\n",
    "            G.add_edge(node, sn)\n",
    "            # print(\"connected edge from \",node, \" to \",sn)\n",
    "            G[node][sn]['weight'] = w\n",
    "            G1.remove_node(sn)\n",
    "    return G\n",
    "\n",
    "def get_path_length(shallow_G, o_node_posns, src_posn, goal_posn, occ_grid, k):\n",
    "    G = shallow_G.copy()\n",
    "    sx, sy = src_posn[0], src_posn[1]\n",
    "    gx, gy = goal_posn[0], goal_posn[1]\n",
    "    G.add_node('s', state = str(sx)+\" \"+str(sy))\n",
    "    G.add_node('g', state = str(gx)+\" \"+str(gy))\n",
    "    for i in range(len(o_node_posns)):\n",
    "        x,y = o_node_posns[i][0], o_node_posns[i][1]\n",
    "        G.add_node('o'+str(i), state = str(x)+\" \"+str(y))\n",
    "    print(\"connecting knn\")    \n",
    "    G = connect_knn(G, k)\n",
    "    print(\"connected knn\")\n",
    "    G = remove_invalid_edges(G, occ_grid)\n",
    "    path_length = None\n",
    "    path_node_posns = []\n",
    "    try:\n",
    "        path_length = nx.dijkstra_path_length(G,'s','g', weight = 'weight')\n",
    "        path_nodes = nx.dijkstra_path(G, 's', 'g', weight = 'weight')\n",
    "        for node in path_nodes:\n",
    "            path_node_posns.append(state_to_numpy(G.node[node]['state']))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return path_length, path_node_posns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('count = ', 0)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 150)\n",
      "connected knn\n",
      "('removed ', 238, 'edges')\n",
      "('path_length = ', 1.029665814471348)\n",
      "('count = ', 1)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 181)\n",
      "connected knn\n",
      "('removed ', 213, 'edges')\n",
      "('path_length = ', 1.085342450743854)\n",
      "('count = ', 2)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 172)\n",
      "connected knn\n",
      "('removed ', 237, 'edges')\n",
      "('path_length = ', 1.1065190270937137)\n",
      "('count = ', 3)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 163)\n",
      "connected knn\n",
      "('removed ', 229, 'edges')\n",
      "('path_length = ', 1.182115623170327)\n",
      "('count = ', 4)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 175)\n",
      "connected knn\n",
      "('removed ', 258, 'edges')\n",
      "('path_length = ', 0.925192485472046)\n",
      "('count = ', 5)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 169)\n",
      "connected knn\n",
      "('removed ', 212, 'edges')\n",
      "('path_length = ', 1.1864930097238096)\n",
      "('count = ', 6)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 168)\n",
      "connected knn\n",
      "('removed ', 217, 'edges')\n",
      "('path_length = ', None)\n",
      "('count = ', 7)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 158)\n",
      "connected knn\n",
      "('removed ', 243, 'edges')\n",
      "('path_length = ', 0.8801582651332368)\n",
      "('count = ', 8)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 168)\n",
      "connected knn\n",
      "('removed ', 221, 'edges')\n",
      "('path_length = ', 0.669178253735449)\n",
      "('count = ', 9)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 169)\n",
      "connected knn\n",
      "('removed ', 266, 'edges')\n",
      "('path_length = ', None)\n",
      "('count = ', 10)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 150)\n",
      "connected knn\n",
      "('removed ', 245, 'edges')\n",
      "('path_length = ', None)\n",
      "('count = ', 11)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 164)\n",
      "connected knn\n",
      "('removed ', 247, 'edges')\n",
      "('path_length = ', 0.9605395424960157)\n",
      "('count = ', 12)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 173)\n",
      "connected knn\n",
      "('removed ', 242, 'edges')\n",
      "('path_length = ', 0.6201069493670469)\n",
      "('count = ', 13)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 168)\n",
      "connected knn\n",
      "('removed ', 242, 'edges')\n",
      "('path_length = ', 0.4898376313420737)\n",
      "('count = ', 14)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 154)\n",
      "connected knn\n",
      "('removed ', 257, 'edges')\n",
      "('path_length = ', 1.1003248482655719)\n",
      "('count = ', 15)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 171)\n",
      "connected knn\n",
      "('removed ', 214, 'edges')\n",
      "('path_length = ', 1.2236059029445885)\n",
      "('count = ', 16)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 170)\n",
      "connected knn\n",
      "('removed ', 263, 'edges')\n",
      "('path_length = ', 0.9652668095697494)\n",
      "('count = ', 17)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 156)\n",
      "connected knn\n",
      "('removed ', 229, 'edges')\n",
      "('path_length = ', 0.6500241877741451)\n",
      "('count = ', 18)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 162)\n",
      "connected knn\n",
      "('removed ', 236, 'edges')\n",
      "('path_length = ', 0.914331311117252)\n",
      "('count = ', 19)\n",
      "got node posns\n",
      "connecting knn\n",
      "('no of nodes = ', 158)\n",
      "connected knn\n",
      "('removed ', 257, 'edges')\n",
      "('path_length = ', None)\n",
      "[1.029665814471348, 1.085342450743854, 1.1065190270937137, 1.182115623170327, 0.925192485472046, 1.1864930097238096, None, 0.8801582651332368, 0.669178253735449, None, None, 0.9605395424960157, 0.6201069493670469, 0.4898376313420737, 1.1003248482655719, 1.2236059029445885, 0.9652668095697494, 0.6500241877741451, 0.914331311117252, None]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from math import sqrt\n",
    "# cond_test = []\n",
    "# test_cases = []\n",
    "# for x in range(10):\n",
    "#     test_cases.append(randint(0,numTest-1))\n",
    "\n",
    "# test_cases = [1379]\n",
    "shallow_G = load_halton_samples()\n",
    "num_viz = 100\n",
    "path_lengths = []\n",
    "all_path_nodes_posns = []\n",
    "k = 10\n",
    "count = 0\n",
    "# print(test_cases)\n",
    "# print(conditions[0])\n",
    "# return\n",
    "failed_c = 0\n",
    "for cond in conditions:\n",
    "#     print(\"---------------------------------------cond = \",cond)\n",
    "#     if(count<7):\n",
    "#         count+=1\n",
    "#         continue\n",
    "    print(\"count = \", count)\n",
    "    o_node_posns = get_o_node_posns(cond, num_viz, count)\n",
    "    print(\"got node posns\")\n",
    "    occ_grid = cond[4:].reshape(10,10)\n",
    "#     print(occ_grid)\n",
    "#     break\n",
    "#     print(o_node_posns)\n",
    "    path_length, path_node_posns = get_path_length(shallow_G, o_node_posns, cond[:2], cond[2:4], occ_grid, k)\n",
    "    path_lengths.append(path_length)\n",
    "    if(path_length==None):\n",
    "        failed_c += 1\n",
    "    print(\"path_length = \", path_length)\n",
    "    all_path_nodes_posns.append(path_node_posns)\n",
    "    count += 1\n",
    "print(path_lengths)\n",
    "print(failed_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
